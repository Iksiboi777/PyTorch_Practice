{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INITIALIZATION\n",
    "# !pip install opendatasets --quiet\n",
    "# import opendatasets as od\n",
    "# od.download(\"https://www.kaggle.com/datasets/marquis03/bean-leaf-lesions-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d278dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA PATHS\n",
    "train_df = pd.read_csv('bean-leaf-lesions-classification/train.csv')\n",
    "val_df = pd.read_csv('bean-leaf-lesions-classification/val.csv')\n",
    "\n",
    "data_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "data_df['image:FILE'] = \"bean-leaf-lesions-classification/\" + data_df['image:FILE']\n",
    "\n",
    "print(\"Data shape is: \", data_df.shape)\n",
    "print()\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA INSPECTION\n",
    "print(\"Classes are: \")\n",
    "print(data_df[\"category\"].unique())\n",
    "print()\n",
    "print(\"Classes distrubution are: \")\n",
    "print(data_df[\"category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc323e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SPLIT\n",
    "train = data_df.sample(frac=0.7, random_state=42)\n",
    "test = data_df.drop(train.index)\n",
    "print(\"Train shape is: \", train.shape)\n",
    "print(\"Test shape is: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a24595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING OBJECTS\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Improved training transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    # IMPORTANT: Use ImageNet normalization stats for transfer learning\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN,\n",
    "                         std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Validation transforms should be minimal\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN,\n",
    "                         std=IMAGENET_STD),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0)\n",
    "])\n",
    "\n",
    "# v2 STYLE\n",
    "NUM_CLASSES = 3\n",
    "cutmix = v2.CutMix(num_classes=NUM_CLASSES, alpha=0.5)\n",
    "mixup = v2.MixUp(num_classes=NUM_CLASSES, alpha=0.5)\n",
    "\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333eafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM DATASET CLASS\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from PIL import Image\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "class AdvancedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    An advanced dataset class with several improvements:\n",
    "    1. Reads data from a CSV file for more flexible annotation.\n",
    "    2. Can handle different \"modes\" (train/val) with different transforms.\n",
    "    3. Converts images to \"RGB\" to handle grayscale or RGBA images robustly.\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "                               Expected columns: 'image_name', 'label'.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                                            on a sample.\n",
    "        \"\"\"\n",
    "        self.annotations_df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            img_name = os.path.join(self.root_dir, self.annotations_df.iloc[index, 0])\n",
    "            image = Image.open(img_name).convert(\"RGB\")\n",
    "            \n",
    "            # ============================\n",
    "            # =====> FIX WAS HERE <=====\n",
    "            # ============================\n",
    "            # Return a simple Python integer, not a tensor.\n",
    "            label = int(self.annotations_df.iloc[index, 1])\n",
    "            # ============================\n",
    "\n",
    "            # Apply per-image transformations\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data at index {index}: {e}\")\n",
    "            # Return None to be filtered by the collate_fn if needed,\n",
    "            # or handle more gracefully. For now, we'll let it raise.\n",
    "            raise e\n",
    "    \n",
    "\n",
    "def collate_fn_with_v2_aug(batch, v2_transform=None):\n",
    "    \"\"\"\n",
    "    A custom collate_fn that takes a batch of data from AdvancedDataset\n",
    "    and applies batch-level v2 augmentations before stacking them into a tensor.\n",
    "    \n",
    "    Args:\n",
    "        batch (list of tuples): A list where each element is a tuple \n",
    "                                (image_tensor, label_tensor).\n",
    "        v2_transform (callable, optional): A v2 transform like CutMix or MixUp\n",
    "                                           to be applied to the entire batch.\n",
    "    \"\"\"\n",
    "    # IMAGE STACKING\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "\n",
    "    # Convert the tuple of integer labels into a single 1D tensor\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    if v2_transform:\n",
    "        images, labels = v2_transform(images, labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# CREATE DATASET OBJECTS\n",
    "train_dataset = AdvancedDataset(csv_file='bean-leaf-lesions-classification/train.csv',\n",
    "                                root_dir='bean-leaf-lesions-classification',\n",
    "                                transform=train_transforms)\n",
    "\n",
    "val_dataset = AdvancedDataset(csv_file='bean-leaf-lesions-classification/val.csv',\n",
    "                              root_dir='bean-leaf-lesions-classification',\n",
    "                              transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e232d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS AND DATALOADING\n",
    "config = {\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 15,\n",
    "    \"num_classes\": 3,\n",
    "    \"weight_decay\": 0.01\n",
    "}\n",
    "\n",
    "print(\"\\nTraining Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "# --- 3. DATALOADER INSTANTIATION ---\n",
    "# Now, we use these robust components to create our DataLoaders.\n",
    "\n",
    "# Assuming 'train_dataset', 'val_dataset', and 'cutmix_or_mixup' are defined\n",
    "# from the previous steps. And 'config' dictionary exists.\n",
    "\n",
    "# Use functools.partial for a cleaner way to pass args to the collate_fn\n",
    "train_collate_fn = partial(collate_fn_with_v2_aug, v2_transform=cutmix_or_mixup)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=2, # Set based on your system\n",
    "    collate_fn=train_collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn_with_v2_aug # No v2 transform needed for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab731aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# googlenet_model = models.googlenet(weights='DEFAULT')\n",
    "# for param in googlenet_model.parameters():\n",
    "#   param.requires_grad = True\n",
    "\n",
    "# googlenet_model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING\n",
    "from tqdm.autonotebook import tqdm\n",
    "import time\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, scheduler, device):\n",
    "    \"\"\"\n",
    "    Execute a single training epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    lrs = []\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Training\", leave=False)\n",
    "                    # tqdm(dataloader, desc=f\"Epoch {mode} Progress\"):\n",
    "\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        # print(f\"Train outputs size: {outputs.size()} \")\n",
    "        loss = criterion(outputs, labels)\n",
    "        # loss_aux1 = criterion(outputs.aux_logits1, labels)\n",
    "        # loss_aux2 = criterion(outputs.aux_logits2, labels)\n",
    "        # loss = loss_main + 0.3 * loss_aux1 + 0.3 * loss_aux2\n",
    "\n",
    "        # main_preds = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        scheduler.step()\n",
    "        lrs.append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        # print(f\"Train preds size: {preds.size()} \")\n",
    "        # print(f\"Labels size: {labels.size()}\")\n",
    "\n",
    "        if labels.dim() > 1:\n",
    "            true_labels = torch.argmax(labels, dim=1)\n",
    "        else:\n",
    "            true_labels = labels\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += (preds == true_labels).sum().item()\n",
    "        # torch.sum(preds == labels.data)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item(), acc=running_corrects/total_samples)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc, lrs\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Starting training process...\")\n",
    "\n",
    "# Initialize a dictionary to store the training history for later plotting\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [], \n",
    "    'train_acc': [], 'val_acc': [], \n",
    "    'lrs': []\n",
    "}\n",
    "\n",
    "model = models.googlenet(weights=None, aux_logits=True)\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Modify the main classifier\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, config[\"num_classes\"])\n",
    "\n",
    "# 2. Modify the first auxiliary classifier\n",
    "num_ftrs_aux1 = model.aux1.fc2.in_features\n",
    "model.aux1.fc2 = nn.Linear(num_ftrs_aux1, config[\"num_classes\"])\n",
    "\n",
    "# 3. Modify the second auxiliary classifier\n",
    "num_ftrs_aux2 = model.aux2.fc2.in_features\n",
    "model.aux2.fc2 = nn.Linear(num_ftrs_aux2, config[\"num_classes\"])\n",
    "# ============================\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76fc171",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), \n",
    "                 lr=config[\"lr\"], \n",
    "                 weight_decay=config[\"weight_decay\"]\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler_diff_train(scheduler):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "        train_loss, train_acc, lrs = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scheduler, device\n",
    "        )\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lrs'].extend(lrs)\n",
    "\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "    print(f\"\\n🏁 Training finished in {total_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CosineAnnealingLR SCHEDULER\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config[\"epochs\"]\n",
    "    # steps_per_epoch=len(train_dataset), #does it change with the data augmentation\n",
    "    # epochs=config[\"epochs\"]\n",
    ")\n",
    "\n",
    "scheduler_diff_train(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea31fc",
   "metadata": {},
   "source": [
    "<h2>10. Promijeni kod za korištenje StepLR scheduler</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# --- NEW: StepLR Scheduler ---\n",
    "# This scheduler will decrease the LR by a factor of 0.1 every 5 epochs.\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "print(\"\\n✅ Model, AdamW Optimizer, and FINAL StepLR Scheduler initialized.\")\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# STAGE 2: TRAINING AND EVALUATION FUNCTIONS (UNCHANGED)\n",
    "# ==================================\n",
    "# The `train_one_epoch` and `evaluate` functions from the previous version are correct\n",
    "# and do not need to be changed. We'll include them here for completeness.\n",
    "\n",
    "def train_one_epoch_step(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # loss_aux1 = criterion(outputs.aux_logits1, labels)\n",
    "        # loss_aux2 = criterion(outputs.aux_logits2, labels)\n",
    "        # loss = loss_main + 0.3 * loss_aux1 + 0.3 * loss_aux2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        if labels.dim() > 1:\n",
    "            true_labels = torch.argmax(labels, dim=1)\n",
    "        else:\n",
    "            true_labels = labels\n",
    "        correct_predictions += (preds == true_labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        progress_bar.set_postfix(loss=loss.item(), acc=correct_predictions/total_samples)\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_step(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            progress_bar.set_postfix(loss=loss.item(), acc=correct_predictions/total_samples)\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# ==================================\n",
    "# STAGE 3: MAIN TRAINING LOOP (WITH \"SAVE BEST\" LOGIC)\n",
    "# ==================================\n",
    "print(\"\\n🚀 Starting training process with stable strategy and 'save best' logic...\")\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'lrs': []}\n",
    "start_time = time.time()\n",
    "\n",
    "# Variables to track the best performing model\n",
    "best_val_acc = 0.0\n",
    "best_model_weights = None\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{config['epochs']} ---\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch_step(model, train_loader, criterion, optimizer, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    \n",
    "    val_loss, val_acc = evaluate_step(model, val_loader, criterion, device)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # The epoch-level StepLR scheduler is stepped after the validation step\n",
    "    scheduler.step()\n",
    "    history['lrs'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    print(f\"Epoch Summary: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "          \n",
    "    # ============================\n",
    "    # =====> NEW LOGIC HERE <=====\n",
    "    # ============================\n",
    "    # Check if the current model is the best one we've seen so far\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # Save a deep copy of the model's weights\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        print(f\"🎉 New best model saved with validation accuracy: {best_val_acc:.4f}\")\n",
    "    # ============================\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"\\n🏁 Training finished in {total_time:.2f} seconds.\")\n",
    "print(f\"🏆 Best validation accuracy achieved: {best_val_acc:.4f}\")\n",
    "\n",
    "# After the loop, you can load the best weights back into the model for final evaluation\n",
    "if best_model_weights:\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    print(\"\\n✅ Best model weights loaded for final analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7affe9",
   "metadata": {},
   "source": [
    "<h4>Idemo sa StepLR i checkpointanjem dalje<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#\n",
    "#       FINAL ANALYSIS, VISUALIZATION, AND SAVING SUITE\n",
    "#\n",
    "# This script consumes the results from the training process to:\n",
    "# 1. Plot detailed training curves (loss, accuracy, learning rate).\n",
    "# 2. Save the best performing model's weights and configuration to a file.\n",
    "# 3. Provide an example of how to load the saved model for future use.\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# STAGE 1: PLOT TRAINING & VALIDATION CURVES\n",
    "# ==================================\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss/accuracy, as well as the \n",
    "    learning rate schedule from a training history dictionary.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plotting Loss\n",
    "    axes[0].plot(history['train_loss'], label='Training Loss')\n",
    "    axes[0].plot(history['val_loss'], label='Validation Loss')\n",
    "    axes[0].set_title('Loss vs. Epochs')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plotting Accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Training Accuracy')\n",
    "    axes[1].plot(history['val_acc'], label='Validation Accuracy')\n",
    "    axes[1].set_title('Accuracy vs. Epochs')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"📈 Plotting training history...\")\n",
    "plot_training_history(history)\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# STAGE 2: SAVE THE BEST MODEL AND PARAMETERS\n",
    "# ==================================\n",
    "\n",
    "# First, ensure the model has the best weights loaded\n",
    "if best_model_weights:\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    print(\"\\n✅ Best model weights have been loaded into the model.\")\n",
    "\n",
    "# Define a path for saving the model\n",
    "save_path = \"best_model.pth\"\n",
    "\n",
    "\n",
    "# Create a dictionary to save everything needed for reproducibility\n",
    "checkpoint = {\n",
    "    'config': config,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'best_val_acc': best_val_acc # From the training loop\n",
    "}\n",
    "\n",
    "# Save the checkpoint dictionary to the file\n",
    "torch.save(checkpoint, save_path)\n",
    "print(f\"💾 Model and configuration saved successfully to '{save_path}'\")\n",
    "\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# STAGE 3: EXAMPLE OF LOADING THE SAVED MODEL\n",
    "# ==================================\n",
    "# This demonstrates how you would use your saved model in a different script.\n",
    "\n",
    "def load_model_for_inference(path):\n",
    "    \"\"\"Loads a saved checkpoint for inference.\"\"\"\n",
    "    \n",
    "    # Load the saved checkpoint\n",
    "    checkpoint = torch.load(path)\n",
    "    \n",
    "    # Get the saved configuration\n",
    "    saved_config = checkpoint['config']\n",
    "    \n",
    "    # Re-create the model architecture using the saved config\n",
    "    loaded_model = models.get_model(saved_config[\"model_name\"], pretrained=False) # No need to download weights\n",
    "    num_ftrs = loaded_model.fc.in_features\n",
    "    loaded_model.fc = nn.Linear(num_ftrs, saved_config[\"num_classes\"])\n",
    "    \n",
    "    # Load the saved weights into the model\n",
    "    loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(\"\\n✅ Model loaded successfully from checkpoint.\")\n",
    "    print(f\"   - Original Model: {saved_config['model_name']}\")\n",
    "    print(f\"   - Trained for: {saved_config['epochs']} epochs\")\n",
    "    print(f\"   - Achieved Val Acc: {checkpoint['best_val_acc']:.4f}\")\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "# Demonstrate loading the model we just saved\n",
    "inference_model = load_model_for_inference(save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dipl_pro_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
